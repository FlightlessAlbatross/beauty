{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the rural_beauty module\n"
     ]
    }
   ],
   "source": [
    "# model specific info\n",
    "from rural_beauty.config import data_dir, models_dir \n",
    "import importlib\n",
    "\n",
    "module_name = \"rural_beauty.config\"\n",
    "para_outcome = 'scenic'\n",
    "para_type = 'randomforest'\n",
    "sugar    =  '111124'  # random identifier to have different models with same other paras\n",
    "country = 'UK'\n",
    "\n",
    "model_basename = f\"{country}_{para_outcome}_{para_type}_{sugar}\"\n",
    "model_folder = models_dir / model_basename\n",
    "\n",
    "if not os.path.exists(models_dir / model_basename):\n",
    "    os.mkdir(models_dir / model_basename)\n",
    "\n",
    "# Import the module\n",
    "config_module = importlib.import_module(module_name)\n",
    "\n",
    "# Dynamically construct the variable name\n",
    "feature_paths   = getattr(config_module, f\"feature_paths_{country}\")\n",
    "BFN_features    = getattr(config_module, f\"BFN_features_{para_outcome}\")\n",
    "predictors_path = getattr(config_module, f\"predictors_{country}\")\n",
    "outcome_path    = getattr(config_module, f\"outcome_{country}\")\n",
    "\n",
    "\n",
    "model_path = model_folder / 'model.pkl'\n",
    "scaler_X_path = model_folder / 'scaling_X.pkl'\n",
    "scaler_Y_path = model_folder / 'scaling_Y.pkl'\n",
    "significant_coefs_path = model_folder / \"significant_coefs.csv\"\n",
    "\n",
    "output_raster_path = model_folder / 'prediction.tif'\n",
    "\n",
    "boundary_gpd_path = data_dir / 'cleaned' / 'NUTS' / 'EU_main.geojson'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model, the scaling and the significant coefficients. \n",
    "model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "# Load the features paths dict\n",
    "with open(feature_paths, 'r') as input_file:\n",
    "    feature_filepaths = json.load(input_file)\n",
    "    feature_filepaths = {k: Path(v) for k, v in feature_filepaths.items()} \n",
    "\n",
    "significant_coefs = pd.read_csv(significant_coefs_path)\n",
    "significant_filepaths = {feature : feature_filepaths[feature] for feature in significant_coefs.Feature}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New base directory for the adjusted rasters\n",
    "new_base_dir =  data_dir / 'forprediction'\n",
    "\n",
    "new_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create new list of file paths for the adjusted rasters\n",
    "adjusted_raster_paths = {var:new_base_dir / model_basename / f\"{raster_path.name}\" for var, raster_path in significant_filepaths.items()}\n",
    "\n",
    "os.makedirs(new_base_dir / model_basename, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def subset_normalize_and_align_rasters(raster_paths:dict, output_paths:dict, scaler_path:Path) -> None: \n",
    "    \"\"\"\n",
    "    Subset all rasters to the largest area contained within all inputs,\n",
    "    align them to the same resolution and extent, and normalize the data using a saved scaler.\n",
    "\n",
    "    Args:\n",
    "    - raster_paths (list of str): List of file paths to the input rasters.\n",
    "    - output_paths (list of str): List of output file paths to save the aligned and normalized rasters.\n",
    "    - scaler_path (str): Path to the .pkl file containing the fitted StandardScaler.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    # Open all rasters and get their bounds\n",
    "    bounds_list = []\n",
    "    transforms = []\n",
    "    crs = None\n",
    "\n",
    "    for path in raster_paths.values():\n",
    "        with rasterio.open(path) as src:\n",
    "            bounds_list.append(src.bounds)\n",
    "            transforms.append(src.transform)\n",
    "            if crs is None:\n",
    "                crs = src.crs  # Assuming all rasters are in the same CRS, else reproject would be needed.\n",
    "\n",
    "    # Calculate the largest common intersection (extent)\n",
    "    intersection_bounds = (\n",
    "        max([b.left for b in bounds_list]),   # Left bound\n",
    "        max([b.bottom for b in bounds_list]), # Bottom bound\n",
    "        min([b.right for b in bounds_list]),  # Right bound\n",
    "        min([b.top for b in bounds_list])     # Top bound\n",
    "    )\n",
    "\n",
    "    ref_resolution = 1000\n",
    "    pixel_width = ref_resolution\n",
    "    pixel_height = ref_resolution\n",
    "    width = int((intersection_bounds[2] - intersection_bounds[0]) / pixel_width)\n",
    "    height = int((intersection_bounds[3] - intersection_bounds[1]) / pixel_height)\n",
    "\n",
    "    # Align rasters to this common extent\n",
    "    for (varname, raster_path), output_path in zip(raster_paths.items(), output_paths.values()):\n",
    "\n",
    "        # make output dir if it doesn't exist already. \n",
    "        os.makedirs(output_path.parent, exist_ok=True)\n",
    "\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            # Calculate the transform for the common extent\n",
    "            transform, _, _ = calculate_default_transform(\n",
    "                src.crs, src.crs, width=width, height=height, \n",
    "                left=intersection_bounds[0], bottom=intersection_bounds[1], \n",
    "                right=intersection_bounds[2], top=intersection_bounds[3])\n",
    "\n",
    "            # Create a new dataset with the common extent\n",
    "            kwargs = src.meta.copy()\n",
    "            kwargs.update({\n",
    "                'height': height,\n",
    "                'width': width,\n",
    "                'transform': transform\n",
    "            })\n",
    "            print(f\"Aligning and normalizing {raster_path}. Dimensions: {width}, {height}\")\n",
    "\n",
    "            # Read, reproject, and normalize the data, then save\n",
    "            with rasterio.open(output_path, 'w', **kwargs) as dst:\n",
    "                for i in range(1, src.count + 1):  # Reproject and normalize all bands\n",
    "                    # Allocate an array to hold the reprojected data\n",
    "                    reprojected_data = np.empty((height, width), dtype=src.dtypes[i - 1])\n",
    "                    \n",
    "                    reproject(\n",
    "                        source=rasterio.band(src, i),\n",
    "                        destination=reprojected_data,\n",
    "                        src_transform=src.transform,\n",
    "                        src_crs=src.crs,\n",
    "                        dst_transform=transform,\n",
    "                        dst_crs=src.crs,\n",
    "                        resampling=Resampling.nearest  # You can change this to another method if needed\n",
    "                    )\n",
    "\n",
    "                    # Write the normalized data to the output file\n",
    "                    dst.write(reprojected_data, i)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/dem/neighborhood/DEM_EU_range_scaled_zone3.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/dem/neighborhood/DEM_EU_range_scaled_zone1_2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/dem/DEM_EU_range_scaled.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/dem/neighborhood/DEM_EU_range_scaled_zone3_4.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/dem/neighborhood/DEM_EU_range_scaled_zone2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_wald_zone1_4.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_acker_zone1_4.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/osm/neighborhood/len_scaled_streets_EU_4647_zone1_2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_acker_zone1_2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_stoer_zone3.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_weide.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_landwi.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_wanat.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_acker.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_natur.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/osm/len_scaled_streets_EU_4647.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/protected/WDPA_area_scaled.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_schatt.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_selten.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_natgru_zone2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_natgru_zone1_2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_stoer_zone1_2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_kraut.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_bebau.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_stoer_zone2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_wald.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_geholz.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_siedl.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_dorf.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/osm/len_scaled_powerlines_EU_4647.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_heide.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_feucht.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_nwald.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_moor.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_natgru.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_lwald.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_noveg_zone2.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_mwald.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_stoer.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/neighborhood/code_obst_zone1_4.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_gewage.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_semage.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_spfr.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_strauc.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_gewae.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_seemee.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_offen.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_noveg.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_indgew.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_seen.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_meer.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_abbau.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_stgrue.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_flug.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_gezei.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_stadt.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_obswei.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_strbah.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_suempf.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_fels.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_gwlf.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_obst.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_salzw.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_hafen.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_sand.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/osm/neighborhood/freq_scaled_windpowerplants_EU_4647_zone1_4.tif. Dimensions: 6564, 4058\n",
      "Aligning and normalizing /h/u145/hofer/MyDocuments/Granular/beauty/data/cleaned/clc/layer_coverage_EU/code_wein.tif. Dimensions: 6564, 4058\n"
     ]
    }
   ],
   "source": [
    "subset_normalize_and_align_rasters(significant_filepaths, adjusted_raster_paths, scaler_X_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.transform import from_origin\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "# Function to read and check for values outside the valid range in predictor GeoTIFFs\n",
    "def check_invalid_values(predictor_paths):\n",
    "    for var_name, path in predictor_paths.items():\n",
    "        with rasterio.open(path) as tif:\n",
    "            data = tif.read(1)  # Read the first (and only) band\n",
    "            if np.any(np.isnan(data)):\n",
    "                print(f\"Warning: {var_name} contains NaN values.\")\n",
    "            if np.any(np.isinf(data)):\n",
    "                print(f\"Warning: {var_name} contains infinity values.\")\n",
    "            if np.any(data > np.finfo(np.float32).max):\n",
    "                print(f\"Warning: {var_name} contains values too large for dtype 'float32'.\")\n",
    "            if np.any(data < np.finfo(np.float32).min):\n",
    "                print(f\"Warning: {var_name} contains values too small for dtype 'float32'.\")\n",
    "\n",
    "# Function to create a prediction GeoTIFF\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "# Function to create a prediction GeoTIFF within a specified polygon\n",
    "\n",
    "def create_prediction_geotiff(model, predictor_paths, output_raster_path, polygon_gdf):\n",
    "    \"\"\"\n",
    "    Generate a prediction GeoTIFF using a trained RandomForest model and a set of predictor rasters,\n",
    "    but only predict values within a given polygon.\n",
    "\n",
    "    Args:\n",
    "    - model: A fitted RandomForest model.\n",
    "    - predictor_paths: Dictionary of predictor variable names and their corresponding raster paths.\n",
    "    - output_raster_path: File path to save the output prediction raster.\n",
    "    - polygon_gdf: A GeoDataFrame containing a single polygon.\n",
    "\n",
    "    \"\"\"\n",
    "    # Read the first GeoTIFF to get metadata\n",
    "    with rasterio.open(list(predictor_paths.values())[0]) as src:\n",
    "        profile = src.profile\n",
    "        profile.update(\n",
    "            dtype=rasterio.float32,\n",
    "            count=1,  # single band for prediction\n",
    "            nodata=-9999  # Set the nodata value for the output\n",
    "        )\n",
    "\n",
    "        # Convert the polygon to the same CRS as the raster\n",
    "        polygon = polygon_gdf.to_crs(src.crs)\n",
    "\n",
    "        # Create a mask from the polygon to define the area for prediction\n",
    "        mask = geometry_mask([geometry for geometry in polygon.geometry],\n",
    "                             transform=src.transform, invert=True,\n",
    "                             out_shape=(src.height, src.width))\n",
    "\n",
    "        # Read all predictor GeoTIFFs and stack them into a 3D array\n",
    "        predictors = []\n",
    "        combined_mask = mask  # Initialize combined mask with polygon mask\n",
    "        for path in predictor_paths.values():\n",
    "            with rasterio.open(path) as tif:\n",
    "                data = tif.read(1)\n",
    "                predictors.append(data)\n",
    "                # Update combined mask to consider areas with NA values\n",
    "                combined_mask &= ~np.isnan(data)  # True where data is valid\n",
    "\n",
    "        # Convert list of 2D arrays into a single 3D array (stacked along axis 0)\n",
    "        predictors = np.stack(predictors, axis=2)\n",
    "        n_rows, n_cols, n_features = predictors.shape\n",
    "\n",
    "        # Mask the predictors to ignore areas outside the polygon or where values are NA\n",
    "        predictors[~combined_mask] = np.nan\n",
    "\n",
    "        # Flatten the masked 3D array for prediction, ignoring NaN values\n",
    "        valid_data = predictors[combined_mask].reshape(-1, n_features)\n",
    "        predictions = model.predict(valid_data)\n",
    "\n",
    "        # Create an empty prediction array and fill it only in masked areas\n",
    "        prediction_array = np.full((n_rows, n_cols), -9999, dtype=np.int32)  # Use -9999 for nodata\n",
    "        prediction_array[combined_mask] = predictions.astype(np.int32)\n",
    "\n",
    "    # Write the prediction array to a new GeoTIFF\n",
    "    with rasterio.open(output_raster_path, 'w', **profile) as dst:\n",
    "        dst.write(prediction_array, 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_invalid_values({'dem_1': significant_filepaths['dem_1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load boundary polygon\n",
    "import geopandas as gpd\n",
    "boundary_gpd  = gpd.read_file(boundary_gpd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_prediction_geotiff(model, adjusted_raster_paths, output_raster_path, boundary_gpd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
