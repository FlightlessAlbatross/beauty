{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to call the main python functions to preprocess, extract data for training, model training and predict a tif.\n",
    "\n",
    "Generally using this notebook is not recommended over calling the data extration, training and prediction scripts from the command line. \n",
    "\n",
    "The notebook takes about twice as long.\n",
    "\n",
    "\n",
    "\n",
    "TODO: explain the config file and folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rural_beauty.config import models_dir\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from rural_beauty import preprocessing         # function to get from the raw data to cleaned data ready for extraction. \n",
    "from rural_beauty import get_data_for_training # the function to create model data frames\n",
    "from rural_beauty import training_model        # the function to train a tree model\n",
    "from rural_beauty import predict_generic       # the function to predict a tif based on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing needs the raw (as downloaded form source) data, and converts them to 1x1km resolution geotiffs. \n",
    "\n",
    "Aggregations are usually the share of the area within a pixel. \n",
    "\n",
    "E.g:\n",
    "\n",
    "     Forest.tif: \"Share of the pixel that is covered by Forests\"\n",
    "\n",
    "     protected.tif: share of the pixel that is part of a protected area. \n",
    "\n",
    "\n",
    "preprocessing.py does the calculations for every layer we consider wholesale. Individual groups of inputs can be skipped using flags. --skip_CLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.main()\n",
    "\n",
    "# options to skip:\n",
    "# preprocessing.main( --skip_DE --skip_UK --skip_CLC --skip_DEM --skip_OSM --skip_Hemerobie --no-skip_Protected --skip_Neighborhood)\n",
    "\n",
    "# right now some steps overwrite and some steps skip if the output files are already present. This is a TODO. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_data_for_training.py`\n",
    "\n",
    "This script extracts data from preprocessed raster files based on a specified sampling method and country. The resulting data is formatted into tabular form and saved as CSV files, making it ready for ingestion by machine learning workflows.\n",
    "\n",
    "### Key Features:\n",
    "- **Flexible Sampling Methods**: Supports different sampling strategies such as extracting all raster pixels, random sampling, or using predefined points (e.g., UK scenic points).\n",
    "- **Multi-Feature Extraction**: Combines raster-based predictors with outcome variables for a unified dataset.\n",
    "- **Polygon Support**: Handles extractions within specific boundary polygons and supports buffering to include coastal areas.\n",
    "\n",
    "### Sampling Methods:\n",
    "For Germany there are random_pixels and all_pixels. \n",
    "For UK we have implemented pooled_pixels_random_points and pooled_pixels_all_points. \n",
    "\n",
    "pooled_pixels refers to the fact that we can have multiple scenic or not images within the same 1km gridcell.  \n",
    "pooled_pixels pools the ratings of all images within a cell together.  \n",
    "Additionally, when we sample, we only sample pixels that have images in them, and do not interpolate.  \n",
    "If needed we can extend all and random pixels to UK by first interpolating the scenic or not rating so all pixels, but this seems worse, so it is not implemented.  \n",
    "\n",
    "Possible future methods could treat same pixel images, separatly.  \n",
    "\n",
    "### Outputs:\n",
    "The script generates tabular data saved in the following directory structure:\n",
    "\n",
    "The tabular data is saved as .csvs in at: data / models / __extracted_points / {country} / {sampling} / \n",
    "\n",
    "\n",
    "### Files Created:\n",
    "1. **`coords.csv`**: Coordinates of the sampled points.\n",
    "2. **`predictors.csv`**: Raster-based explanatory variables extracted at the points.\n",
    "3. **`outcome.csv`**: Target variable values extracted at the same points.\n",
    "4. **`features.json`**: Metadata containing the paths to the raster files used for extraction.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example Usage:\n",
    "\n",
    "To extract data for Germany (`DE`) using the `all_pixels` sampling method for the `beauty` target variable:\n",
    "```bash\n",
    "python3 get_data_for_training.py DE beauty all_pixels\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files exist\n",
      "Extracting beauty's raster values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting explanatory raster values: 100%|██████████| 68/68 [01:25<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate file written to /h/u145/hofer/MyDocuments/Granular/beauty/data/models/__extracted_points/DE/beauty/random_pixels/coords.csv\n",
      "Outcome file written to /h/u145/hofer/MyDocuments/Granular/beauty/data/models/__extracted_points/DE/beauty/random_pixels/outcome.csv\n",
      "Predictors file written to /h/u145/hofer/MyDocuments/Granular/beauty/data/models/__extracted_points/DE/beauty/random_pixels/predictors.csv\n",
      "Feature path json written to /h/u145/hofer/MyDocuments/Granular/beauty/data/models/__extracted_points/DE/beauty/random_pixels/feature_paths.json\n"
     ]
    }
   ],
   "source": [
    "# here we set parameters fo\n",
    "# parameters for data generation\n",
    "country = 'DE'\n",
    "target_variable = 'beauty'\n",
    "sampling_method = 'all_pixels' # extracting all_pixels will take a long time. 60+ min on the IIASA VM101 server. \n",
    "\n",
    "get_data_for_training.main(country=country, target_variable =  target_variable, sampling_method=sampling_method)\n",
    "# python3 rural_beauty/rural_beauty/get_data_for_training.py DE beauty all_pixels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model Training Script: `train_model.py`\n",
    "\n",
    "This script trains machine learning models on preprocessed spatial and raster data for Germany (`DE`) or the United Kingdom (`UK`). The output includes trained models, evaluation metrics, and visualizations to support further analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Features\n",
    "- **Flexible Model Selection**: Supports various machine learning models, including:\n",
    "  - `RandomForestClassifier`\n",
    "  - `DecisionTreeClassifier`\n",
    "  - `XGBClassifier`\n",
    "- **Hyperparameter Tuning**: Optional grid search for optimal model parameters.\n",
    "- **Data Balancing**: Handles unbalanced classes through oversampling or uses data as is.\n",
    "- **Sampling Strategies**: Tailored for spatial data, offering:\n",
    "  - `all_pixels`: Extracts all raster values.\n",
    "  - `random_pixels`: Samples random raster values.\n",
    "  - `pooled_pixels_all_points`: For UK, pools multiple scenic values within a grid cell.\n",
    "  - `pooled_pixels_random_points`: For UK, randomly samples grid cells with images.\n",
    "\n",
    "---\n",
    "\n",
    "#### Inputs\n",
    "1. **Country**: Specify the target country (`DE` or `UK`).\n",
    "2. **Target Variable**: Options include `scenic`, `beauty`, `unique`, or `diverse`.\n",
    "3. **Sampling Method**: Choose the strategy for spatial data sampling.\n",
    "4. **Model Class**: Select the model to train (`RandomForestClassifier`, `DecisionTreeClassifier`, or `XGBClassifier`).\n",
    "5. **Number of Classes**: Set the number of classes for classification.\n",
    "6. **`sugar`**: Unique identifier for the model output folder.\n",
    "7. **Class Balance**:\n",
    "   - `asis`: Use data as is.\n",
    "   - `oversampling`: Balance classes by oversampling underrepresented classes.\n",
    "\n",
    "---\n",
    "\n",
    "#### Outputs\n",
    "All results are saved under the directory:  \n",
    "`data/models/{country}__{target_variable}__{sampling_method}__{model_class}__{class_balance}__{sugar}/`\n",
    "\n",
    "##### Files Created:\n",
    "1. **Trained Model**:\n",
    "   - Saved as `model.pkl` for later predictions.\n",
    "2. **Confusion Matrix**:\n",
    "   - Visualized and saved as `confusion_matrix.png`.\n",
    "3. **Significant Coefficients**:\n",
    "   - CSV file of important features (if supported by the model).\n",
    "4. **Logfile**:\n",
    "   - Appends training summaries (accuracy, F1 score, Kendall's Tau).\n",
    "\n",
    "---\n",
    "\n",
    "#### Evaluation Metrics\n",
    "The script computes the following metrics for model evaluation:\n",
    "- **Accuracy**: Overall prediction correctness.\n",
    "- **F1 Score**: Weighted harmonic mean of precision and recall.\n",
    "- **Kendall's Tau**: Measures rank correlation between predictions and true labels.\n",
    "\n",
    "---\n",
    "\n",
    "#### Command-Line Usage\n",
    "Run the script with the following arguments:\n",
    "\n",
    "```bash\n",
    "python train_model.py <country> <target_variable> <model_class> <sampling_method> <number_classes> <sugar> [--tune-hyperparameters] [--class_balance <method>]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:      0.78\n",
      "Model F1:            0.77\n",
      "Model Kendall's Tau: 0.83\n",
      "Confusion matrix saved to: /h/u145/hofer/MyDocuments/Granular/beauty/data/models/DE__beauty__random_pixels__XGB__asis__7_021224/confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is for training the model\n",
    "model_class      = 'DecisionTreeClassifier'\n",
    "class_balance    = 'asis'\n",
    "number_classes   = 7\n",
    "sugar            = str(number_classes) + '_'+ '191224'\n",
    "\n",
    "\n",
    "\n",
    "# python3 rural_beauty/rural_beauty/training_model.py DE beauty XGB all_pixels asis 7 7_123456\n",
    "training_model.main(country          = country,\n",
    "                    target_variable  = target_variable,\n",
    "                    model_class      = model_class,\n",
    "                    sampling_method  = sampling_method,\n",
    "                    class_balance    = class_balance,\n",
    "                    sugar            = sugar,\n",
    "                    number_classes   = number_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively we can train a whole group of models.\n",
    "Lets set up a short list of models we want to try out and then run all the combinations of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['DE', 'UK']\n",
    "# for the target variable the choice depends on the country so we set up a dictionary. \n",
    "target_variables = {'DE': 'beauty', 'UK': 'scenic'}\n",
    "model_classes = ['XGB', 'RandomForestClassifier', 'DecisionTreeClassifier']\t\n",
    "class_balances = ['asis', 'oversampling']\n",
    "# we leave the number of classes and the sugar as they are.\n",
    "\n",
    "# the results are both stored in new folders in the models directory, but also the results are stored in \n",
    "# a logfile at data/models/logfile.txt\n",
    "\n",
    "for country in countries:\n",
    "  for model_class in model_classes:\n",
    "    for class_balance in class_balances:\n",
    "        training_model.main(country          = country,\n",
    "                            target_variable  = target_variables[country],\n",
    "                            model_class      = model_class,\n",
    "                            sampling_method  = sampling_method,\n",
    "                            class_balance    = class_balance,\n",
    "                            sugar            = sugar,\n",
    "                            number_classes   = number_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting EU-Wide Values Using Trained Models\n",
    "\n",
    "This script generates predictions for the EU (as defined by ) based on trained machine learning models and raster data. It aligns and normalizes input rasters, evaluates model features, and creates GeoTIFF outputs with predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features\n",
    "- **Flexible Model Parsing**: Dynamically extracts model metadata from folder names, enabling seamless integration with trained models.\n",
    "- **Raster Alignment and Normalization**:\n",
    "  - Ensures all input rasters have a common extent and resolution.\n",
    "  - Subsets and aligns rasters to focus on areas of interest.\n",
    "- **Boundary-Based Predictions**:\n",
    "  - Predictions are constrained to specified regions (e.g., NUTS polygons) with optional buffering for coastal areas.\n",
    "- **GeoTIFF Outputs**:\n",
    "  - Generates prediction rasters in GeoTIFF format for easy visualization and integration with GIS tools.\n",
    "- **Robust Validations**:\n",
    "  - Checks for invalid values (e.g., NaNs, infinities) in predictor rasters.\n",
    "  - Handles missing or misaligned data gracefully.\n",
    "\n",
    "---\n",
    "\n",
    "### Workflow\n",
    "1. **Input Data Preparation**:\n",
    "   - Loads trained model and feature rasters.\n",
    "   - Aligns rasters to a common extent and resolution.\n",
    "2. **Prediction Generation**:\n",
    "   - Reads rasters and stacks them for input into the machine learning model.\n",
    "   - Applies model predictions only within specified boundaries (e.g., polygons from NUTS data).\n",
    "3. **Output**:\n",
    "   - Creates a prediction GeoTIFF with nodata values (-99) for areas outside the polygon or with invalid inputs.\n",
    "   - Saves prediction rasters and logs relevant information.\n",
    "\n",
    "---\n",
    "\n",
    "### Inputs\n",
    "1. **Model Folder**:\n",
    "   - The folder containing the trained model, e.g., `data/models/DE__unique__random_pixels__XGB__asis__7_271124`.\n",
    "   - Includes the model file (`model.pkl`), features, and training metadata.\n",
    "2. **Boundary Data**:\n",
    "   - GeoJSON file specifying polygons for the prediction region (e.g., EU boundaries with NUTS data).\n",
    "\n",
    "---\n",
    "\n",
    "### Outputs\n",
    "1. **Prediction GeoTIFF**:\n",
    "   - File path: `<model_folder>/prediction.tif`\n",
    "   - Contains model predictions for valid regions, aligned to the input rasters.\n",
    "2. **Aligned Rasters**:\n",
    "   - Adjusted rasters saved under `data/forprediction/[boundary_name]`.\n",
    "3. **Logs**:\n",
    "   - Validation logs for raster alignment, invalid values, and prediction summaries.\n",
    "\n",
    "---\n",
    "\n",
    "### Command-Line Usage\n",
    "Run the script with the following arguments:\n",
    "\n",
    "```bash\n",
    "python predict_eu.py <model_folder> <boundary_path>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing the prediction to /h/u145/hofer/MyDocuments/Granular/beauty/data/models/DE__beauty__random_pixels__XGB__asis__7_021224/prediction.tif\n"
     ]
    }
   ],
   "source": [
    "# the prediction function takes a model folder (as crated by the training function)\n",
    "model_basename = f\"{country}__{target_variable}__{sampling_method}__{model_class}__{class_balance}__{sugar}\" # instead use something like \"__\".join(**kargs)\n",
    "model_folder   = models_dir / model_basename\n",
    "\n",
    "from beauty.config import NUTS_EU, NUTS_DE, NUTS_UK\n",
    "\n",
    "# predict_generic.main(model_folder, NUTS_EU)\n",
    "# alternatively we can cross predict the model on the other country for all the models we set up the grid for\n",
    "\n",
    "for country in countries:\n",
    "    for model_class in model_classes:\n",
    "        for class_balance in class_balances:\n",
    "            model_basename = f\"{country}__{target_variable}__{sampling_method}__{model_class}__{class_balance}__{sugar}\" # instead use something like \"__\".join(**kargs)\n",
    "            model_folder   = models_dir / model_basename\n",
    "            if country == 'DE':\n",
    "                predict_generic.main(model_folder, NUTS_UK)\n",
    "            else:\n",
    "                predict_generic.main(model_folder, NUTS_DE)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
